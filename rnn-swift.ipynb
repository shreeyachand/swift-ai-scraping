{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a535c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'tswiftlyrics.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbbeaafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 08:36:20.214759: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef346822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Verse 1]\n",
      "I walked through the door with you, the air was cold\n",
      "But somethin' 'bout it felt like home somehow\n",
      "And I left my scarf there at your sister's house\n",
      "And you've still got it in your drawer, even now\n",
      "\n",
      "[Verse 2]\n",
      "Oh, your sweet disposition and m\n"
     ]
    }
   ],
   "source": [
    "text = open(path, 'rb').read().decode(encoding='utf-8').strip(\"\\n\")\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24514dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 706287 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822a7626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 unique characters\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(str(len(chars)) + ' unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df359488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '\\xa0',\n",
       " 'é',\n",
       " 'í',\n",
       " 'ó',\n",
       " 'е',\n",
       " '\\u2005',\n",
       " '\\u200b',\n",
       " '–',\n",
       " '—',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '…',\n",
       " '\\u205f']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5557c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 08:36:24.638836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b's', b'h', b'r', b'e', b'e', b'y', b'a'],\n",
       " [b'h', b'e', b'l', b'l', b'o']]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = ['shreeya', 'hello']\n",
    "c = tf.strings.unicode_split(ex, input_encoding='UTF-8')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1efc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_to_id = tf.keras.layers.StringLookup(vocabulary=list(chars), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188b7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[74, 63, 73, 60, 60, 80, 56], [63, 60, 67, 67, 70]]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_to_id(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f51a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_ch = tf.keras.layers.StringLookup(vocabulary=list(chars), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04ab2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b's', b'h', b'r', b'e', b'e', b'y', b'a'],\n",
       " [b'h', b'e', b'l', b'l', b'o']]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_ch(ch_to_id(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff03830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_text(ids):\n",
    "    return tf.strings.reduce_join(id_to_ch(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2aab1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'shreeya', b'hello'], dtype=object)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_text(ch_to_id(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0362683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(706287,), dtype=int64, numpy=array([54, 49, 60, ..., 56, 75, 60])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_id = ch_to_id(tf.strings.unicode_split(text, input_encoding='UTF-8'))\n",
    "all_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc4bb4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "V\n",
      "e\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "1\n",
      "]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_dataset = tf.data.Dataset.from_tensor_slices(all_id)\n",
    "for ids in id_dataset.take(10):\n",
    "    print(id_to_ch(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ade17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d31935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'[' b'V' b'e' b'r' b's' b'e' b' ' b'1' b']' b'\\n' b'I' b' ' b'w' b'a'\n",
      " b'l' b'k' b'e' b'd' b' ' b't' b'h' b'r' b'o' b'u' b'g' b'h' b' ' b't'\n",
      " b'h' b'e' b' ' b'd' b'o' b'o' b'r' b' ' b'w' b'i' b't' b'h' b' ' b'y'\n",
      " b'o' b'u' b',' b' ' b't' b'h' b'e' b' ' b'a' b'i' b'r' b' ' b'w' b'a'\n",
      " b's' b' ' b'c' b'o' b'l' b'd' b'\\n' b'B' b'u' b't' b' ' b's' b'o' b'm'\n",
      " b'e' b't' b'h' b'i' b'n' b\"'\" b' ' b\"'\" b'b' b'o' b'u' b't' b' ' b'i'\n",
      " b't' b' ' b'f' b'e' b'l' b't' b' ' b'l' b'i' b'k' b'e' b' ' b'h' b'o'\n",
      " b'm' b'e'], shape=(100,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = id_dataset.batch(seq_len, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(id_to_ch(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e501b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"[Verse 1]\\nI walked through the door with you, the air was cold\\nBut somethin' 'bout it felt like home\", shape=(), dtype=string)\n",
      "tf.Tensor(b\" somehow\\nAnd I left my scarf there at your sister's house\\nAnd you've still got it in your drawer, ev\", shape=(), dtype=string)\n",
      "tf.Tensor(b\"en now\\n\\n[Verse 2]\\nOh, your sweet disposition and my wide-eyed gaze\\nWe're singin' in the car, getting\", shape=(), dtype=string)\n",
      "tf.Tensor(b\" lost upstate\\nAutumn leaves fallin' down like pieces into place\\nAnd I can picture it after all these\", shape=(), dtype=string)\n",
      "tf.Tensor(b\" days\\n\\n[Pre-Chorus]\\nAnd I know it's long gone and\\nThat magic's not here no more\\nAnd I might be okay,\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(id_to_text(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4db85e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41de7ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['S', 'h', 'r', 'e', 'e', 'y'], ['h', 'r', 'e', 'e', 'y', 'a'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Shreeya\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0fbc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "681e4ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"[Verse 1]\\nI walked through the door with you, the air was cold\\nBut somethin' 'bout it felt like hom\"\n",
      "Target: b\"Verse 1]\\nI walked through the door with you, the air was cold\\nBut somethin' 'bout it felt like home\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", id_to_text(input_example).numpy())\n",
    "    print(\"Target:\", id_to_text(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2da50158",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000).batch(64, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7850ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(ch_to_id.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d80e2c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e840f1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "670583c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10bf4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "610b750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "70bda640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 99, 97) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4ea2d91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  24832     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  99425     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6f8b85f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 18, 84, 45, 31, 89, 67,  4, 44, 58, 17, 85, 11, 67, 57, 43, 23,\n",
       "       12,  3, 27, 22,  0, 74, 31, 16, 92, 80, 54, 27, 66, 62, 65, 27, 16,\n",
       "       20, 92,  6, 38, 54, 75, 86, 24,  9,  9, 11, 44, 12, 45, 76, 78, 67,\n",
       "       80, 61, 90, 16, 17, 85, 48, 59, 19, 57,  4, 80, 68, 86, 67, 26, 75,\n",
       "       70, 75, 14, 28, 53, 92, 44, 71, 11, 15, 25, 78, 88, 28, 13, 39, 74,\n",
       "       43,  1, 92, 16, 48, 68, 47, 28, 27,  1, 93,  5, 10, 35])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c916fa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\" like bang, we tried to forget it, but we just couldn't\\nAnd I bury hatchets, but I keep maps of whe\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b'-3\\xc3\\xadRD\\xe2\\x80\\x93l\"Qc2\\xc3\\xb3,lbP8-!?7[UNK]sD1\\xe2\\x80\\x99y[?kgj?15\\xe2\\x80\\x99\\'K[t\\xd0\\xb59**,Q-Ruwlyf\\xe2\\x80\\x9412\\xc3\\xb3Ud4b\"ym\\xd0\\xb5l;tot/AZ\\xe2\\x80\\x99Qp,0:w\\xe2\\x80\\x8bA.LsP\\n\\xe2\\x80\\x991UmTA?\\n\\xe2\\x80\\x9c&+H'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", id_to_text(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", id_to_text(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a087de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e76cbaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 99, 97)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.575602, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f07b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.08647"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "074011ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5bdfd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57df4109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - 161s 1s/step - loss: 2.9718\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 168s 2s/step - loss: 2.0667\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 174s 2s/step - loss: 1.7415\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 180s 2s/step - loss: 1.5267\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 165s 1s/step - loss: 1.3733\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 167s 2s/step - loss: 1.2536\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 176s 2s/step - loss: 1.1519\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 169s 2s/step - loss: 1.0586\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 172s 2s/step - loss: 0.9709\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 172s 2s/step - loss: 0.8866\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 176s 2s/step - loss: 0.8040\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 169s 2s/step - loss: 0.7225\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 179s 2s/step - loss: 0.6424\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 179s 2s/step - loss: 0.5700\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 164s 1s/step - loss: 0.5022\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 175s 2s/step - loss: 0.4410\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 191s 2s/step - loss: 0.3867\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 187s 2s/step - loss: 0.3398\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 182s 2s/step - loss: 0.3028\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 178s 2s/step - loss: 0.2704\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=20, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6793332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, id_to_ch, ch_to_id, temperature=1.14):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.id_to_ch = id_to_ch\n",
    "        self.ch_to_id = ch_to_id\n",
    "\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ch_to_id(input_chars).to_tensor()\n",
    "\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                              return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        predicted_chars = self.id_to_ch(predicted_ids)\n",
    "\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef44f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, id_to_ch, ch_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5237333d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_step_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hr/w9mgqspd3bdf6tk_drk2jkjm0000gp/T/ipykernel_59686/3670199871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_step_model' is not defined"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['['])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "print(result[0].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d538ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aca89973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7faa89fe7850>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.load_weights('./training_checkpoints/ckpt_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1f4d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model_loaded = OneStep(model_load, id_to_ch, ch_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "825bd926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chorus]\n",
      "Didn't shake it off\n",
      "I, I, I shake I wouldn't be exavitytice\n",
      "'Cause you weren undrouth (Yeah, oh, yeah)\n",
      "There you ever heard out up with you\n",
      "Smile agains in your very first den and gon't go fie\n",
      "\n",
      "[Chorus]\n",
      "So it's gonna give you when you're sleeping\n",
      "Keep your ey-eyes open\n",
      "\n",
      "[Verse 2]\n",
      "There's the fight of our live out dees, but never be somewhere, we're going down ‘roude and Cried\n",
      "\n",
      "[Chorus]\n",
      "\"Come on an onvenseat of what I ever)\n",
      "Screaming, \"I'm in love with you\"\n",
      "Wait there in the pourin' rain, coming back forever, everything is wrong\n",
      "It rains when you're here and it rains when you're gonna (I know place)\n",
      "\"Oh my God, look at that fall back on you)\n",
      "Let my slil my love as, umberies and falling up now\n",
      "But if I was a month on how tonight\n",
      "All you drive me crazy chancing, sunny, Surfrife\n",
      "\n",
      "[Pre-Chorus]\n",
      "And it would be a flawe them\n",
      "Every tim from the balcory\n",
      "Even though the whole tcrow\n",
      "Know you better than that\n",
      "Huy you don’t know what you middled man\n",
      "I got myself it in a new harder on a twinf\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['['])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model_loaded.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "print(result[0].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d4f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
